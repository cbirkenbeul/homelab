---
# yaml-language-server: $schema=https://kubernetes-schemas.devbu.io/postgresql.cnpg.io/cluster_v1.json
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: pgvecto
  namespace: database
spec:
  instances: 3
  imageName: ghcr.io/tensorchord/cloudnative-pgvecto.rs:14.11-v0.2.0
  primaryUpdateStrategy: unsupervised
  storage:
    size: 10Gi
    storageClass: local-hostpath
  enableSuperuserAccess: true
  superuserSecret:
    name: cloudnative-pg-secret
  # bootstrap:
  #   recovery:
  #     source: &previous-cluster pgvecto-v3 #This must match backup.barmanObjectStore.serverName from previous backup
  postgresql:
    shared_preload_libraries:
      - "vectors.so"
    parameters:
      max_connections: "600"
      shared_buffers: 512MB
  monitoring:
    enablePodMonitor: true
  backup:
    retentionPolicy: 30d
    barmanObjectStore:
      data:
        compression: bzip2
      wal:
        compression: bzip2
        maxParallel: 8
      destinationPath: s3://cloudnative-pg/
      endpointURL: https://s3.teqqnet.de
      serverName: &currentCluster pgvecto
      s3Credentials:
        accessKeyId:
          name: cloudnative-pg-secret
          key: aws-access-key-id
        secretAccessKey:
          name: cloudnative-pg-secret
          key: aws-secret-access-key
  # Note: externalClusters is needed when recovering from an existing cnpg cluster
  # externalClusters:
  #   - name: *previous-cluster
  #     barmanObjectStore:
  #       wal:
  #         compression: bzip2
  #         maxParallel: 8
  #       destinationPath: *dest-path
  #       endpointURL: *endpoint-url
  #       s3Credentials: *s3-creds